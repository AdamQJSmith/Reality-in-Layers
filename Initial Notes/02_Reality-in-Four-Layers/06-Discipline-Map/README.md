## 6  Discipline Map – Which Handle Does Each Field Grab First?

This section groups major research domains by the **primary evidence handle** they use when approaching the Layer 4 validation gate. The clusters are not silos; many projects borrow handles from multiple layers. Still, the map clarifies why fields rely on different methods and why cross‑talk so often misfires.

### 6.1 Four primary clusters

| Cluster (examples)                                                                        | Dominant source layer(s)                | Typical data / phenomena                                                                | Leading Layer 4 methods                                                                | What counts as success                                          |
| ----------------------------------------------------------------------------------------- | --------------------------------------- | --------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **Physical sciences** – physics, chemistry, astronomy                                     | L1                                      | Instrument readings, repeatable measurements, controlled perturbations                  | Mathematical modelling, prediction‑error tests, blind replication                      | Precise quantitative fit and novel predictions                  |
| **Life sciences** – molecular biology, physiology, ecology                                | L1 + L2                                 | Molecular assays, imaging, field surveys, comparative anatomy                           | Statistical inference, mechanistic modelling, perturb‑and‑observe experiments          | Explanatory power over structure–function relations             |
| **Mind sciences** – psychology, psychiatry, cognitive neuroscience, consciousness studies | L2 + L3                                 | Behavioural tasks, neural‐signal patterns, symptom interviews, phenomenological reports | Mixed‑model statistics, factor analysis, qualitative coding, triangulation             | Joint convergence of neural, behavioural, and experiential data |
| **Normative & social fields** – ethics, aesthetics, economics, political theory           | L3 (plus L2 organisms and L1 resources) | Moral intuitions, aesthetic responses, price movements, institutional practices         | Reflective equilibrium, historical comparison, game‑theoretic or econometric modelling | Coherence, normative appeal, predictive or policy utility       |

---

### 6.2 Why physics looks "hard" and ethics looks "soft"

*Physics* starts with an L1 handle that offers high signal‑to‑noise, so small discrepancies trigger sharp falsification tests. *Ethics* starts with an L3 handle awash in perspective bias, so it relies more on coherence, case comparison, and long‑run reflective stability. The rigour difference is not about laxer rules; it arises from layer‑specific error profiles.

### 6.3 Hybrid research programs

* **Cognitive neuroscience** marries L2 neural codes to L3 reports, demanding tools from both clusters.
* **Environmental ethics** must integrate L1 climate models (physical sciences), L2 species survival data (life sciences), and L3 value judgments (normative field).
* **Behavioural economics** links L3 preferences to L2 decision circuitry and L1 resource constraints.

Successful hybrid fields explicitly weight each handle's error profile rather than smearing them together.

### 6.4 Matrix of routes to objectivity

| Field               | Source layer(s)                           | Data                             | Layer 4 test                | Key failure mode      |
| ------------------- | ----------------------------------------- | -------------------------------- | --------------------------- | --------------------- |
| Particle physics    | L1                                        | Cross‑section counts             | 5σ replication              | Instrument drift      |
| Molecular genetics  | L1 + L2                                   | Gene knock‑out assays            | Reproducible phenotype link | Off‑target effects    |
| Clinical psychiatry | L2 + L3                                   | Symptom scales + imaging         | DSM/ICD reliability         | Diagnostic inflation  |
| Bioethics           | L3 (plus L2 facts)                        | Case intuitions                  | Reflective equilibrium      | Cultural parochialism |
| Macroeconomics      | L3 motives + L2 aggregates + L1 resources | Price indices, sentiment surveys | Model out‑of‑sample fit     | Parameter instability |

(The full comparative matrix is included in Appendix C for readers who need granular detail.)

### 6.5 Using the map

1. **Identify your handle** – Start any project by asking which layer gives you the cleanest initial grip.
2. **Quantify the error profile** – Calibrate instruments, compare species, blind phenomenological coding—whichever bias is native to your handle.
3. **Translate to Layer 4 standards** – Choose the coherence or prediction benchmark that best neutralises the identified bias.
4. **Signal when shifting handles** – Interdisciplinary teams should declare, "Now we are using L3 data; error profile just changed," to avoid invisible category slips.

With the discipline map in place, we can test the framework on concrete cases. The next section walks through colour perception, clinical depression, and monetary inflation—three problems that span the full layer stack. 